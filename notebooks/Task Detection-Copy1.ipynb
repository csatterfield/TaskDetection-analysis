{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load(\"../models/normalized.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from datetime import datetime, date, time\n",
    "from collections import defaultdict, Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import textrank\n",
    "import os\n",
    "import sys\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from rake_nltk import Rake\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter, defaultdict\n",
    "from math import log, floor\n",
    "import numpy as np\n",
    "import textrank\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, precision_recall_fscore_support\n",
    "import pickle\n",
    "import os\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "stop_words = stopwords.words(\"english\")\n",
    "stop_words.extend([\"chris\", \"satterfield\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(dateobj, start, end):\n",
    "    return dateobj >= start and dateobj < end        \n",
    "\n",
    "def rake(snapshot):\n",
    "    r = Rake()\n",
    "    r.extract_keywords_from_text(snapshot)\n",
    "    return r.get_ranked_phrases()\n",
    "\n",
    "\n",
    "def tfidf(task_counters):\n",
    "    idf_counters = []\n",
    "    for counter in task_counters:\n",
    "        n = Counter()\n",
    "        for key in counter:\n",
    "            n[key] = 1\n",
    "        idf_counters.append(n)\n",
    "    total_counter = sum(idf_counters, Counter())\n",
    "    \n",
    "    weighted_counters = []\n",
    "    for counter in task_counters:\n",
    "        occurances = []\n",
    "        for key in counter.keys():\n",
    "            occurances.append(total_counter[key])\n",
    "        \n",
    "        mean = np.mean(occurances)\n",
    "        \n",
    "        weighted = {}\n",
    "        for key in counter.keys():\n",
    "            weighted[key] = counter[key]/((total_counter[key])  * (1 + abs(mean - total_counter[key])))\n",
    "        weighted_counters.append(Counter(weighted))\n",
    "    return weighted_counters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffleDict(dictionary):\n",
    "    keys = list(dictionary.keys())\n",
    "    random.shuffle(keys)\n",
    "    shuffled = {}\n",
    "    for key in keys:\n",
    "        shuffled[key] = dictionary[key]\n",
    "    \n",
    "    return shuffled\n",
    "\n",
    "def equals(prediction, expected):\n",
    "    if(prediction == expected):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_prediction(scores):\n",
    "    scores = shuffleDict(scores)\n",
    "    return max(scores, key=scores.get)\n",
    "\n",
    "def normalize_score(scores):\n",
    "    norm = np.linalg.norm(list(scores.values()))\n",
    "    for score in scores:\n",
    "        scores[score] = scores[score]/norm\n",
    "    return scores\n",
    "\n",
    "\n",
    "class ScreenshotTaskExtractor(object):\n",
    "\n",
    "    def __init__(self, vocab):\n",
    "        self.vocab = vocab\n",
    "\n",
    "\n",
    "    def isProbablyEmail(self, task):\n",
    "        excludedWords = ['compose', 'gmail', 'inbox', 'google', 'starred', 'sent','mail','drafts','more','terms','privacy','program','policies']\n",
    "        i = 0\n",
    "        for word in excludedWords:\n",
    "            if word in task:\n",
    "                i += 1\n",
    "        return i > 4\n",
    "\n",
    "    def get_tasks_for_participant(self, path_to_data, participant, without_emails=True, ungrouped=False, filter=lambda x: word_tokenize(x), using_tfidf=False):\n",
    "\n",
    "        with open(f\"{path_to_data}/{participant}/fulltext.pkl\", \"rb\") as f:\n",
    "            snapshotsWithDates = pickle.load(f)\n",
    "        \n",
    "        df = pd.read_excel(f\"{path_to_data}/{participant}/taskswitches_annotated.xlsx\")\n",
    "        offset = df[df[\"task\"] == \"offset\"][\"end\"].iloc[0]\n",
    "        df = df[df[\"task\"] != \"offset\"]\n",
    "        task_words_ungrouped = []\n",
    "        task_order = []\n",
    "\n",
    "        studyStartTime = snapshotsWithDates[0][0] - (datetime.combine(date.min, offset) - datetime.min)\n",
    "\n",
    "        for _,row in df.iterrows():\n",
    "            startDelta = datetime.combine(date.min, row[\"start\"]) - datetime.min \n",
    "            endDelta = datetime.combine(date.min, row[\"end\"]) - datetime.min\n",
    "            start = studyStartTime + startDelta\n",
    "            end = studyStartTime + endDelta\n",
    "\n",
    "            snapshotsInTask = [x[1].lower() for x in snapshotsWithDates if valid(x[0], start, end)]\n",
    "\n",
    "            if(without_emails):\n",
    "                snapshotsInTask = [x for x in snapshotsInTask if not self.isProbablyEmail(x)]\n",
    "\n",
    "            words = []\n",
    "            for snapshot in snapshotsInTask:\n",
    "                tokens = word_tokenize(snapshot)\n",
    "                snapshot_words = [x for x in tokens if len(x) > 2]\n",
    "                #snapshot_words = [stemmer.stem(x) for x in snapshot_words if not x in stop_words and x in self.vocab]\n",
    "                words.extend(snapshot_words)\n",
    "\n",
    "            if(len(words) > 0):\n",
    "                task_words_ungrouped.append(words)\n",
    "                task_order.append(row[\"task\"])\n",
    "        \n",
    "        task_counters = [Counter(x) for x in task_words_ungrouped]\n",
    "        if(not ungrouped):\n",
    "            counters = defaultdict(Counter)\n",
    "            for counter, task in zip(task_counters, task_order):\n",
    "                counters[task] += counter\n",
    "            task_order, task_counters = zip(*counters.items())\n",
    "        \n",
    "        #for task in task_counters:\n",
    "        #    norm = np.linalg.norm(list(task.values()))\n",
    "        #    for word in task:\n",
    "        #        task[word] = task[word]/norm\n",
    "\n",
    "        return task_counters, task_order\n",
    "    \n",
    "def sim(v1, v2):\n",
    "    return cosine_similarity(v1.reshape(1,-1), v2.reshape(1,-1))[0][0]\n",
    "\n",
    "def create_results(method, predicted, expected, author, participant):\n",
    "    return [{\"method\": method, \"predicted\": x, \"expected\": y, \"author\": author, \"participant\": participant, \"correct\": equals(x, y)} for x,y in zip(predicted, expected)]\n",
    "\n",
    "def predict_simple(tasks, order, phrases):\n",
    "    predictions = []\n",
    "    expected = []\n",
    "    durations = []\n",
    "    sim_vocab = []\n",
    "\n",
    "    for task, actual in zip(tasks, order):\n",
    "        scores = dict()\n",
    "        cover_scores = dict()\n",
    "        expected.append(actual)\n",
    "        words = []\n",
    "        cover = {}\n",
    "        \n",
    "        for _, row in phrases.iterrows():\n",
    "            search_terms = word_tokenize(row[\"phrase\"])\n",
    "            search_terms = [x.lower() for x in search_terms if not x.lower() in stop_words]\n",
    "            search_terms = [x for x in search_terms if len(x) > 2]\n",
    "            #search_terms = [stemmer.stem(x) for x in search_terms if x in model.wv.vocab]\n",
    "            search_terms = list(set(search_terms))\n",
    "\n",
    "            occurs = 0\n",
    "            coverage = 0\n",
    "            covered = []\n",
    "            \n",
    "            for word in search_terms:\n",
    "                if word in task:\n",
    "                    occurs += task[word]\n",
    "                    coverage += 1\n",
    "                    covered.append(word)\n",
    "                    coverage = coverage/len(search_terms)\n",
    "            \n",
    "            scores[row[\"expected\"]] = occurs\n",
    "            cover_scores[row[\"expected\"]] = coverage\n",
    "\n",
    "            cover[row[\"expected\"]] = [(x, task[x]) for x in covered]\n",
    "\n",
    "        scores = normalize_score(scores)\n",
    "        cover_scores = normalize_score(scores)\n",
    "\n",
    "        for key in scores.keys():\n",
    "            scores[key] = scores[key] * 1 + cover_scores[key] * 0\n",
    "\n",
    "        predictions.append(get_prediction(scores))\n",
    "\n",
    "    return predictions, expected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START ----- \n",
      "P01\n",
      "Matching phrases by author: thomas\n",
      "Matching phrases by author: gail\n",
      "END -----\n",
      "START ----- \n",
      "P02\n",
      "Matching phrases by author: thomas\n",
      "Matching phrases by author: gail\n",
      "END -----\n",
      "START ----- \n",
      "P03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/csatterfield/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:23: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching phrases by author: thomas\n",
      "Matching phrases by author: gail\n",
      "END -----\n",
      "START ----- \n",
      "P04\n",
      "Matching phrases by author: thomas\n",
      "Matching phrases by author: gail\n",
      "END -----\n",
      "START ----- \n",
      "P05\n",
      "Matching phrases by author: thomas\n",
      "Matching phrases by author: gail\n",
      "END -----\n",
      "START ----- \n",
      "P06\n",
      "Matching phrases by author: thomas\n",
      "Matching phrases by author: gail\n",
      "END -----\n",
      "START ----- \n",
      "P07\n",
      "Matching phrases by author: thomas\n",
      "Matching phrases by author: gail\n",
      "END -----\n",
      "START ----- \n",
      "P08\n",
      "Matching phrases by author: thomas\n",
      "Matching phrases by author: gail\n",
      "END -----\n",
      "START ----- \n",
      "P11\n",
      "Matching phrases by author: thomas\n",
      "Matching phrases by author: gail\n",
      "END -----\n",
      "START ----- \n",
      "P12\n",
      "Matching phrases by author: thomas\n",
      "Matching phrases by author: gail\n",
      "END -----\n",
      "START ----- \n",
      "P13\n",
      "Matching phrases by author: thomas\n",
      "Matching phrases by author: gail\n",
      "END -----\n",
      "START ----- \n",
      "P14\n",
      "Matching phrases by author: thomas\n",
      "Matching phrases by author: gail\n",
      "END -----\n",
      "START ----- \n",
      "P15\n",
      "Matching phrases by author: thomas\n",
      "Matching phrases by author: gail\n",
      "END -----\n",
      "START ----- \n",
      "P16\n",
      "Matching phrases by author: thomas\n",
      "Matching phrases by author: gail\n",
      "END -----\n",
      "START ----- \n",
      "P17\n",
      "Matching phrases by author: thomas\n",
      "Matching phrases by author: gail\n",
      "END -----\n",
      "START ----- \n",
      "P18\n",
      "Matching phrases by author: thomas\n",
      "Matching phrases by author: gail\n",
      "END -----\n",
      "START ----- \n",
      "P19\n",
      "Matching phrases by author: thomas\n",
      "Matching phrases by author: gail\n",
      "END -----\n",
      "0.6151685393258427\n",
      "(array([0.84615385, 0.74285714, 0.64705882, 0.31451613, 0.7032967 ,\n",
      "       0.9047619 ]), array([0.35483871, 0.43333333, 0.17741935, 0.88636364, 0.94117647,\n",
      "       0.95      ]), array([0.5       , 0.54736842, 0.27848101, 0.46428571, 0.80503145,\n",
      "       0.92682927]), array([62, 60, 62, 44, 68, 60]))\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\"../phrases.xlsx\")    \n",
    "results = []\n",
    "participants = [\"P01\", \"P02\", \"P03\", \"P04\", \"P05\", \"P06\", \"P07\", \"P08\", \"P11\", \"P12\", \"P13\", \"P14\", \"P15\", \"P16\", \"P17\", \"P18\", \"P19\"]\n",
    "path_to_data = \"../../archives/\"\n",
    "task_extractor = ScreenshotTaskExtractor(model.wv.vocab)\n",
    "\n",
    "\n",
    "for participant in participants:\n",
    "    print(\"START ----- \")\n",
    "    print(participant)\n",
    "    \n",
    "    if(participant in cache):\n",
    "        tasks,order = cache[participant]\n",
    "    else:\n",
    "        tasks, order = task_extractor.get_tasks_for_participant(path_to_data, participant, using_tfidf=True, ungrouped=True)\n",
    "        cache[participant] = (tasks, order)\n",
    "    \n",
    "    for author in df[\"author\"].unique():\n",
    "        task_descriptions = df[df[\"author\"] == author]\n",
    "        print(\"Matching phrases by author: \" + author)\n",
    "        predicted,expected = predict_simple(tasks, order, task_descriptions)\n",
    "        r = create_results(\"simple\", predicted, expected, author, participant)\n",
    "        results.extend(r)\n",
    "    print(\"END -----\")\n",
    "\n",
    "y_true = [x[\"expected\"] for x in results]\n",
    "y_pred = [x[\"predicted\"] for x in results]\n",
    "\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "print(precision_recall_fscore_support(y_true, y_pred))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df.to_excel(\"matching_results_ungrouped.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
